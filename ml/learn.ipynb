{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellId": "rtd24hvg6odn9rbv82xc9f"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# %pip install -U plotly==5.11.0 pandas==1.3.5 pytorch_lightning==1.8.0 numpy==1.21.6 ipywidgets==8.0.2 \n",
    "# %pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.12.0+cu116.html\n",
    "# %pip install tensorboard==2.11.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellId": "37emi23szdssau0nque5o8"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import pickle\n",
    "import shutil\n",
    "\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "import torchtext\n",
    "import torch_geometric\n",
    "from tqdm import tqdm\n",
    "import identify_x86_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "h3gyr0cmlyp73wob8u32j",
    "execution_id": "9bcf8f7f-fdb4-4f02-9716-0aad31c04472"
   },
   "source": [
    "## Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellId": "bc4lnea3eu81bilzaduq4v"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 53 superset files!\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "\n",
    "# EXECUTABLE = 'bin_zsh5'\n",
    "# EXECUTABLE = 'bin_gzip'\n",
    "# EXECUTABLE = 'usr_lib_gcc_i686-linux-gnu_8_lto1'\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "superset_files = glob.glob('superset/**/*.superset', recursive=True)\n",
    "superset_files = list(sorted((os.path.getsize(f), f) for f in superset_files))\n",
    "superset_files = [f for s, f in superset_files if s < 10_000_000]\n",
    "random.shuffle(superset_files)\n",
    "# print(*superset_files, sep='\\n')\n",
    "print(f\"Using {len(superset_files)} superset files!\")\n",
    "\n",
    "train_files, test_files = superset_files[:40], superset_files[40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ISN_SIZE = 15\n",
    "\n",
    "def load_superset(filename):\n",
    "    df = pd.read_parquet(filename)\n",
    "    df.code = df.code.map(lambda x: identify_x86_data.INSTR_CODES[x])\n",
    "    df.set_index('addr', inplace=True)\n",
    "    df.sort_index(inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellId": "a4kuv2utmimuoqti0dxmws"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:02<00:00, 18.01it/s]\n"
     ]
    }
   ],
   "source": [
    "from torchtext.vocab import vocab as make_vocab\n",
    "from collections import OrderedDict, Counter\n",
    "\n",
    "# TODO: this vocab should be built over the whole training dataset\n",
    "\n",
    "counts = Counter()\n",
    "\n",
    "for filename in tqdm(train_files):\n",
    "    df = load_superset(filename)\n",
    "    df_counts = df.code.value_counts().to_dict()\n",
    "    counts.update(df_counts)\n",
    "\n",
    "# print(counts)\n",
    "\n",
    "known = { x[0]: i for i, x in enumerate(counts.most_common(200)) }\n",
    "vocab = make_vocab(known, specials=['INVALID', 'UNKNOWN'])\n",
    "vocab.set_default_index(vocab['UNKNOWN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cellId": "b88veikgdzvrr2heltwmr"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "vocab['Dec_r32']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "zdnumwxb0as14zhv62vjw3",
    "execution_id": "99d39910-8333-4ac8-807f-65dcb517e63f"
   },
   "source": [
    "## Build graph from the loaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cellId": "lrocwablabuzcig1qsf5"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from torch_geometric.data import Data\n",
    "from typing import List, Tuple\n",
    "import gc\n",
    "\n",
    "def encode_instructions(instr):\n",
    "    code = torch.tensor(vocab(instr.code.to_list()))\n",
    "    size = torch.tensor(instr['size'].map(lambda x: x-1).values)\n",
    "    labels = torch.tensor(instr['label'].values)\n",
    "\n",
    "    return code, size, labels\n",
    "\n",
    "EDGE_NEXT = 0\n",
    "EDGE_PREV = 1\n",
    "EDGE_OVERLAP = 2\n",
    "EDGE_RELCOUNT = 3\n",
    "\n",
    "class EdgesBuilder:\n",
    "    def __init__(self):\n",
    "        self.idx_buffer = []\n",
    "        self.ty_buffer = []\n",
    "        self.edge_count = 0\n",
    "        self.edge_idx_parts = []\n",
    "        self.edge_ty_parts = []\n",
    "\n",
    "    def add_edge(self, src, dst, kind):\n",
    "        self.idx_buffer.append((src, dst))\n",
    "        self.ty_buffer.append(kind)\n",
    "        self.edge_count += 1\n",
    "        \n",
    "        if len(self.idx_buffer) >= 0x80000: # TODO: tune\n",
    "            self.edge_idx_parts.append(torch.tensor(self.idx_buffer, dtype=torch.long))\n",
    "            self.edge_ty_parts.append(torch.tensor(self.ty_buffer, dtype=torch.long))\n",
    "            self.idx_buffer.clear()\n",
    "            self.ty_buffer.clear()\n",
    "\n",
    "    def build(self):\n",
    "        self.edge_idx_parts.append(torch.tensor(self.idx_buffer, dtype=torch.long))\n",
    "        self.edge_ty_parts.append(torch.tensor(self.ty_buffer, dtype=torch.long))\n",
    "        self.idx_buffer.clear()\n",
    "        self.ty_buffer.clear()\n",
    "\n",
    "        edge_idx = torch.cat(self.edge_idx_parts)\n",
    "        self.edge_idx_parts.clear()\n",
    "        gc.collect()\n",
    "        \n",
    "        edge_ty = torch.cat(self.edge_ty_parts)\n",
    "        self.edge_ty_parts.clear()\n",
    "        gc.collect()\n",
    "\n",
    "        return edge_idx, edge_ty\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.edge_count\n",
    "\n",
    "def build_executable_graph(df):\n",
    "    G = Data()\n",
    "    G.num_nodes = df.shape[0]\n",
    "    G.x_code, G.x_size, G.y = encode_instructions(df)\n",
    "    # the classes are stored as booleans for efficiency\n",
    "    # convert them to long for the loss function\n",
    "    G.y = G.y.to(torch.long)\n",
    "\n",
    "    edges = EdgesBuilder()\n",
    "\n",
    "    t = tqdm(df.iterrows(), total=df.shape[0])\n",
    "    for addr, x in t:\n",
    "        i = df.index.get_loc(addr)\n",
    "        next_addr = addr + x.size\n",
    "        try:\n",
    "            j = df.index.get_loc(next_addr)\n",
    "\n",
    "            edges.add_edge(i, j, EDGE_NEXT)\n",
    "            edges.add_edge(j, i, EDGE_PREV)\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "        for o in range(addr+1, next_addr):\n",
    "            try:\n",
    "                j = df.index.get_loc(o)\n",
    "                edges.add_edge(i, j, EDGE_OVERLAP)\n",
    "                edges.add_edge(j, i, EDGE_OVERLAP)\n",
    "            except KeyError:\n",
    "                pass\n",
    "        if addr % 0x1000 == 0:\n",
    "            t.set_description(f'edges: {len(edges)}')\n",
    "\n",
    "    edge_idx, edge_ty = edges.build()\n",
    "    del edges\n",
    "    gc.collect()\n",
    "\n",
    "    # print(edge_idx.shape)\n",
    "    # print(edge_idx)\n",
    "\n",
    "    # print(edge_ty)\n",
    "\n",
    "    G.num_edges = edge_idx.shape[0]\n",
    "    G.edge_index = torch.swapaxes(edge_idx, 0, 1)\n",
    "    G.edge_type = edge_ty\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cellId": "e1d3wiuf9v7cyl2rgi7ao"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# TODO: use PyG's Dataset class\n",
    "\n",
    "# TODO: now that we have a list of superset files we should be able to create a dataset that caches the graph conversion\n",
    "\n",
    "from torch_geometric.data import Dataset\n",
    "\n",
    "class IdentifyDataset(Dataset):\n",
    "    def __init__(self, files, root, transform=None, pre_transform=None):\n",
    "        self.files = files\n",
    "        super().__init__(root, transform, pre_transform)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return self.files\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return [f'{f}.pt' for f in self.files]\n",
    "\n",
    "    def download(self):\n",
    "        for filename, raw_path in zip(self.raw_file_names, self.raw_paths):\n",
    "            os.makedirs(os.path.dirname(raw_path), exist_ok=True)\n",
    "            shutil.copy(filename, raw_path)\n",
    "\n",
    "    def process(self):\n",
    "        for filename, processed_path in zip(tqdm(self.raw_paths), self.processed_paths):\n",
    "            df = load_superset(filename)\n",
    "\n",
    "            # TODO: I want to do this transformation in rust (python ~~sucks ass~~ is slow)\n",
    "            # either way we would need to implement graph construction in rust for deployment\n",
    "            G = build_executable_graph(df)\n",
    "\n",
    "            if self.pre_filter is not None:\n",
    "                data_list = [data for data in data_list if self.pre_filter(data)]\n",
    "\n",
    "            if self.pre_transform is not None:\n",
    "                data_list = [self.pre_transform(data) for data in data_list]\n",
    "\n",
    "            os.makedirs(os.path.dirname(processed_path), exist_ok=True)\n",
    "            torch.save(G, processed_path)\n",
    "    \n",
    "    def get(self, idx):\n",
    "        data = torch.load(self.processed_paths[idx])\n",
    "        if self.transform is not None:\n",
    "            data = self.transform(data)\n",
    "        return data\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.processed_file_names)\n",
    "\n",
    "train_dataset = IdentifyDataset(train_files, 'data/train')\n",
    "test_dataset = IdentifyDataset(test_files, 'data/test')\n",
    "\n",
    "# G = build_executable_graph(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cellId": "tlayxt3bdowcdoddr1bif"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from torch_geometric.nn import Sequential, RGCNConv, Linear\n",
    "from torch.nn import Embedding, ReLU, Sigmoid\n",
    "import torchmetrics\n",
    "import torchmetrics.classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cellId": "ca5zenizst64jpx3g3xjjk"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "from torch import Tensor\n",
    "\n",
    "class IdentifyModel(torch.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        size_embed_size = 4\n",
    "        code_embed_size = 32\n",
    "\n",
    "        @torch.jit.script\n",
    "        def cat(x1, x2):\n",
    "            return torch.cat([x1, x2], dim=1)\n",
    "\n",
    "        self.model = Sequential('x_code, x_size, edge_index, edge_type', [\n",
    "            (Embedding(num_embeddings=MAX_ISN_SIZE, embedding_dim=size_embed_size), 'x_size -> x_size'),\n",
    "            (Embedding(num_embeddings=len(vocab), embedding_dim=code_embed_size), 'x_code -> x_code'),\n",
    "            (cat, 'x_size, x_code -> x'),\n",
    "            (RGCNConv(size_embed_size + code_embed_size, 24, EDGE_RELCOUNT).jittable(), 'x, edge_index, edge_type -> x'),\n",
    "            ReLU(inplace=True),\n",
    "            (RGCNConv(24, 16, EDGE_RELCOUNT).jittable(), 'x, edge_index, edge_type -> x'),\n",
    "            ReLU(inplace=True),\n",
    "            (RGCNConv(16, 8, EDGE_RELCOUNT).jittable(), 'x, edge_index, edge_type -> x'),\n",
    "            ReLU(inplace=True),\n",
    "            (RGCNConv(8, 4, EDGE_RELCOUNT).jittable(), 'x, edge_index, edge_type -> x'),\n",
    "            ReLU(inplace=True),\n",
    "            Linear(4, 2),\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x_code: Tensor, x_size: Tensor, edge_index: Tensor, edge_type: Tensor) -> Tensor:\n",
    "        return self.model(x_code, x_size, edge_index, edge_type)\n",
    "\n",
    "\n",
    "class LightningModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super(LightningModel, self).__init__()\n",
    "\n",
    "        self.model = IdentifyModel()\n",
    "\n",
    "        self.train_accuracy = torchmetrics.classification.BinaryAccuracy()\n",
    "        self.train_precision = torchmetrics.classification.BinaryPrecision()\n",
    "        self.train_recall = torchmetrics.classification.BinaryRecall()\n",
    "\n",
    "        self.valid_accuracy = torchmetrics.classification.BinaryAccuracy()\n",
    "        self.valid_precision = torchmetrics.classification.BinaryPrecision()\n",
    "        self.valid_recall = torchmetrics.classification.BinaryRecall()\n",
    "\n",
    "\n",
    "    def forward(self, x_code: Tensor, x_size: Tensor, edge_index: Tensor, edge_type: Tensor):\n",
    "        x_out = self.model(x_code, x_size, edge_index, edge_type)\n",
    "\n",
    "        return x_out\n",
    "\n",
    "    def training_step(self, batch, batch_index):\n",
    "        x_code, x_size, edge_index, edge_type = \\\n",
    "            batch.x_code, batch.x_size, batch.edge_index, batch.edge_type\n",
    "\n",
    "        x_out = self.forward(x_code, x_size, edge_index, edge_type)\n",
    "\n",
    "        loss = torch.nn.functional.cross_entropy(x_out, batch.y)\n",
    "\n",
    "        # metrics here\n",
    "        pred = x_out.argmax(-1)\n",
    "        label = batch.y\n",
    "        \n",
    "        self.train_accuracy(pred, label)\n",
    "        self.train_precision(pred, label)\n",
    "        self.train_recall(pred, label)\n",
    "\n",
    "        self.log(\"loss/train\", loss)\n",
    "        self.log(\"accuracy/train\", self.train_accuracy, on_step=True, on_epoch=False)\n",
    "        self.log(\"recall/train\", self.train_recall, on_step=True, on_epoch=False)\n",
    "        self.log(\"precision/train\", self.train_precision, on_step=True, on_epoch=False)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_index):\n",
    "        x_code, x_size, edge_index, edge_type = \\\n",
    "            batch.x_code, batch.x_size, batch.edge_index, batch.edge_type\n",
    "\n",
    "        x_out = self.forward(x_code, x_size, edge_index, edge_type)\n",
    "\n",
    "        #loss = torch.nn.functional.cross_entropy(x_out, batch.y)\n",
    "\n",
    "        pred = x_out.argmax(-1)\n",
    "\n",
    "        self.valid_accuracy(pred, batch.y)\n",
    "        self.valid_precision(pred, batch.y)\n",
    "        self.valid_recall(pred, batch.y)\n",
    "\n",
    "        self.log(\"accuracy/val\", self.valid_accuracy, on_step=True, on_epoch=True)\n",
    "        self.log(\"recall/val\", self.valid_recall, on_step=True, on_epoch=True)\n",
    "        self.log(\"precision/val\", self.valid_precision, on_step=True, on_epoch=True)\n",
    "\n",
    "        return x_out, pred, batch.y\n",
    "\n",
    "    def validation_epoch_end(self, validation_step_outputs):\n",
    "        val_loss = 0.0\n",
    "        num_correct = 0\n",
    "        num_total = 0\n",
    "        num_tp = 0\n",
    "        num_tn = 0\n",
    "        num_fp = 0\n",
    "        num_fn = 0\n",
    "\n",
    "        for output, pred, labels in validation_step_outputs:\n",
    "            val_loss += torch.nn.functional.cross_entropy(output, labels, reduction=\"sum\")\n",
    "\n",
    "        self.log(\"loss/val\", val_loss)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr = 3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cellId": "npknzk750bkdrcncavnsh"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "model = LightningModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cellId": "fknkqidhgskcld5y9r6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LightningModel(\n",
       "  (model): IdentifyModel(\n",
       "    (model): Sequential(\n",
       "      (0): Embedding(15, 4)\n",
       "      (1): Embedding(200, 32)\n",
       "      (2): <torch.jit.ScriptFunction object at 0x7f1e2d7baa20>\n",
       "      (3): RGCNConvJittable_52c1d6(36, 24, num_relations=3)\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): RGCNConvJittable_52c8ae(24, 16, num_relations=3)\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): RGCNConvJittable_52d0fb(16, 8, num_relations=3)\n",
       "      (8): ReLU(inplace=True)\n",
       "      (9): RGCNConvJittable_52db01(8, 4, num_relations=3)\n",
       "      (10): ReLU(inplace=True)\n",
       "      (11): Linear(4, 2, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (train_accuracy): BinaryAccuracy()\n",
       "  (train_precision): BinaryPrecision()\n",
       "  (train_recall): BinaryRecall()\n",
       "  (valid_accuracy): BinaryAccuracy()\n",
       "  (valid_precision): BinaryPrecision()\n",
       "  (valid_recall): BinaryRecall()\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cellId": "ot8f00jygigt8ah5r18mo",
    "execution_id": "cdda3a2f-0c60-41b6-bddf-aef11e9f5185"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda is available: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type            | Params\n",
      "----------------------------------------------------\n",
      "0 | model           | IdentifyModel   | 12.2 K\n",
      "1 | train_accuracy  | BinaryAccuracy  | 0     \n",
      "2 | train_precision | BinaryPrecision | 0     \n",
      "3 | train_recall    | BinaryRecall    | 0     \n",
      "4 | valid_accuracy  | BinaryAccuracy  | 0     \n",
      "5 | valid_precision | BinaryPrecision | 0     \n",
      "6 | valid_recall    | BinaryRecall    | 0     \n",
      "----------------------------------------------------\n",
      "12.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "12.2 K    Total params\n",
      "0.049     Total estimated model params size (MB)\n",
      "/home/dcnick3/.conda/envs/ml/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/dcnick3/.conda/envs/ml/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "`Trainer.fit` stopped: `max_epochs=2000` reached.\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "print(\"Cuda is available:\", torch.cuda.is_available())\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=None)\n",
    "test_loader = DataLoader(test_dataset, batch_size=None)\n",
    "val_loader = DataLoader(test_dataset, batch_size=None)\n",
    "\n",
    "model = LightningModel()\n",
    "num_epochs = 2000\n",
    "# val_check_interval = len(train_loader)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs = num_epochs,\n",
    "    # val_check_interval = val_check_interval,\n",
    "    log_every_n_steps = 1,\n",
    "    accelerator = 'gpu',\n",
    "    enable_progress_bar = False,\n",
    ")\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cellId": "x0k9ezrw7srha0v1u8cee8",
    "execution_id": "1204e816-f3cd-4da7-ba4f-494673020d97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model JIT: RecursiveScriptModule(\n",
      "  original_name=IdentifyModel\n",
      "  (model): RecursiveScriptModule(\n",
      "    original_name=Sequential_530972\n",
      "    (module_0): RecursiveScriptModule(original_name=Embedding)\n",
      "    (module_1): RecursiveScriptModule(original_name=Embedding)\n",
      "    (module_3): RecursiveScriptModule(\n",
      "      original_name=RGCNConvJittable_52ee10\n",
      "      (aggr_module): RecursiveScriptModule(original_name=MeanAggregation)\n",
      "    )\n",
      "    (module_4): RecursiveScriptModule(original_name=ReLU)\n",
      "    (module_5): RecursiveScriptModule(\n",
      "      original_name=RGCNConvJittable_52f810\n",
      "      (aggr_module): RecursiveScriptModule(original_name=MeanAggregation)\n",
      "    )\n",
      "    (module_6): RecursiveScriptModule(original_name=ReLU)\n",
      "    (module_7): RecursiveScriptModule(\n",
      "      original_name=RGCNConvJittable_52ff9a\n",
      "      (aggr_module): RecursiveScriptModule(original_name=MeanAggregation)\n",
      "    )\n",
      "    (module_8): RecursiveScriptModule(original_name=ReLU)\n",
      "    (module_9): RecursiveScriptModule(\n",
      "      original_name=RGCNConvJittable_530804\n",
      "      (aggr_module): RecursiveScriptModule(original_name=MeanAggregation)\n",
      "    )\n",
      "    (module_10): RecursiveScriptModule(original_name=ReLU)\n",
      "    (module_11): RecursiveScriptModule(original_name=Linear)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "# TODO: this is not that easy...\n",
    "# model.eval()\n",
    "# for param in model.parameters():\n",
    "    # param.requires_grad = False\n",
    "model_jit = torch.jit.script(model.model)\n",
    "print(\"Model JIT:\", model_jit)\n",
    "\n",
    "model_jit.save(f\"model_jit.pt\")\n",
    "\n",
    "# torch.onnx.export(model_jit, (\n",
    "#     torch.tensor([0], dtype=torch.long),\n",
    "#     torch.tensor([0], dtype=torch.long),\n",
    "#     torch.tensor([[0, 0]], dtype=torch.long),\n",
    "#     torch.tensor([0], dtype=torch.long),\n",
    "# ), f\"{EXECUTABLE}.onnx\", verbose=True)\n",
    "# with torch.no_grad():\n",
    "\n",
    "    # torch.onnx.export(model, (G.x_code, G.x_size, G.edge_index, G.edge_type), f\"{EXECUTABLE}.onnx\", verbose=True)\n",
    "# torch.jit.save(model, f\"{EXECUTABLE}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.5333, -0.9070,  0.8564, -0.1676],\n",
       "        [-0.2439,  0.8260, -0.6739,  0.1237]], requires_grad=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.model[-1].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "notebookId": "a155bcf5-968b-4cf3-90b6-eed71f0d9eb7",
  "notebookPath": "learn.ipynb",
  "vscode": {
   "interpreter": {
    "hash": "ee189fb280569f94aaba768fbc6f9a6e82e99133f07daf3aeaa1af78f799e3c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
